{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#VISHVJEET THAKUR\n",
        "##vishwjeetthakur995@gmail.com  \n",
        "##9310334736\n",
        "##PEC(Punjab Engineering College, Chandigarh)"
      ],
      "metadata": {
        "id": "ww7Wz4ZIIMgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Language Model Training - Joke Generator![Joke-generator flow2.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SrwPEd2KIwk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Collection-\n",
        "We will  scrap jokes from a website having but the websites show more codes dynamically , for that we need a tool that can mimic a browser and clicks on 'load more' button to generate more jokes . For that tool or software we can use selenium. We will scrape around 3000 jokes for the demo purpose , as it will be having smaller vocabulary.\n",
        "\n",
        "What is Selenium?\n",
        "Selenium is a tool that mimics human interaction with a web browser. It can:\n",
        "\n",
        "Click buttons (like \"Load More\" buttons)\n",
        "Scroll the page to load additional content\n",
        "Scrape dynamic data (like jokes that are loaded after clicking)\n",
        "\n",
        "Other Alternatives that we may have used: Beautiful soup along with requests library of Python and Scrapy too as it has some very good prebuild modules which makes the scraping easy.\n",
        "\n",
        "How Are We Collecting the Jokes?\n",
        "Open the Jokes Website: We use Selenium to navigate to the jokes page.\n",
        "->Click the “Load More” Button: Each time we click it, new jokes are loaded.->\n",
        "Scroll to View New Content: We scroll the page to bring the \"Load More\" button into view.->\n",
        "Collect the Jokes: Each joke is extracted from the page and saved to a text file."
      ],
      "metadata": {
        "id": "3hRX9euL6OIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-browser chromium-chromedriver\n",
        "!pip install selenium webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k25WPGsMus7",
        "outputId": "2ee7d448-4144-4add-8e36-fa83b82ebadd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 5,484 B/129 kB 4%] [Connected to\r                                                                                                    \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,192 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,532 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Fetched 18.0 MB in 2s (7,485 kB/s)\n",
            "^C\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 30.2 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.2 MB in 2s (17.3 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 123840 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.66.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.66.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.66.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 124069 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.4.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && apt install ./google-chrome-stable_current_amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQyM-HI-Pb8S",
        "outputId": "b5549b84-eac3-459b-bdfe-ecd676346a28",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-07 16:36:58--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 74.125.196.190, 74.125.196.91, 74.125.196.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|74.125.196.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112377704 (107M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 107.17M   117MB/s    in 0.9s    \n",
            "\n",
            "2024-12-07 16:36:59 (117 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [112377704/112377704]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 10.9 MB/123 MB of archives.\n",
            "After this operation, 417 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.2 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 131.0.6778.108-1 [112 MB]\n",
            "Fetched 10.9 MB in 2s (5,349 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 124097 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (131.0.6778.108-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up google-chrome-stable (131.0.6778.108-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set paths for Chrome and ChromeDriver\n",
        "os.environ['PATH'] += ':/usr/lib/chromium-browser/'\n",
        "os.environ['PATH'] += ':/usr/bin/'"
      ],
      "metadata": {
        "id": "ws3DuBE0O2WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "\n",
        "def create_driver():\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chrome_options.add_argument('--disable-extensions')\n",
        "    chrome_options.add_argument('--remote-debugging-port=9222')\n",
        "    chrome_options.add_argument('--disable-gpu')\n",
        "    chrome_options.add_argument('--disable-software-rasterizer')\n",
        "\n",
        "\n",
        "    chrome_options.binary_location = '/usr/bin/chromium-browser'\n",
        "\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service('/usr/bin/chromedriver'), options=chrome_options)\n",
        "    return driver\n"
      ],
      "metadata": {
        "id": "sbM4U0cFM98W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "def get_all_content():\n",
        "    driver = create_driver()\n",
        "    driver.get('https://www.laughfactory.com/jokes')\n",
        "    click_count=0\n",
        "    while click_count<501:\n",
        "        try:\n",
        "            load_more_button = driver.find_element(By.XPATH, \"//a[@id='loaderBtn']\")\n",
        "            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", load_more_button)\n",
        "            time.sleep(0.15)\n",
        "            load_more_button.click()\n",
        "            time.sleep(0.15)\n",
        "            click_count+=1\n",
        "        except Exception as e:\n",
        "            print(f\"error- {e}\")\n",
        "            break\n",
        "    jokes = driver.find_elements(By.XPATH, \"//p[starts-with(@id, 'joke_')]\")\n",
        "    jokes_collected = len(jokes)\n",
        "    print(f\"Jokes collected: {jokes_collected}\")\n",
        "\n",
        "    with open(\"laugh_factory_jokes.txt\", \"w\") as file:\n",
        "          for joke in jokes:\n",
        "            file.write(joke.text.strip() + '\\n')\n",
        "    print(f\"Saved {len(jokes)} jokes to file.\")\n",
        "    driver.quit()\n",
        "\n",
        "get_all_content()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLZZgK_LY8y3",
        "outputId": "80f1dc4e-f476-48f7-ad8a-d0e402d87a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jokes collected: 3012\n",
            "Saved 3012 jokes to file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "All jokes are saved in a file -  laugh_factory_jokes.txt, now we need to process it a little bit as few jokes cover two line so we will make them in one line, other than this not much processing is require , we can process it a little bit but lets not so that we can try to make it more human."
      ],
      "metadata": {
        "id": "LNeim9Ez7Jr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def combine_qa_lines(input_file, output_file):\n",
        "    \"\"\"Combines Q: and A: parts in a single line.\"\"\"\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            if line.startswith(\"Q:\"):\n",
        "                if \"A:\" in line:\n",
        "                  outfile.write(line)\n",
        "                else:\n",
        "                  line = re.sub(r'\\n$', ' ', line)\n",
        "                  outfile.write(line)\n",
        "            else:\n",
        "                outfile.write(line)\n",
        "\n",
        "input_file = \"laugh_factory_jokes.txt\"\n",
        "output_file = \"laugh_factory_jokes_mod.txt\"\n",
        "combine_qa_lines(input_file, output_file)"
      ],
      "metadata": {
        "id": "CHC5xXvWo4SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Creating a custom dataset:\n",
        "Transforming the .txt file into a custom data set which our model can easily use to train upon.\n",
        "# Process\n",
        "Tokenize the text — Convert words into numbers using a pre-trained GPT2TOkenizer.->\n",
        "Pad or truncate the sequences — Ensure every joke fits within a fixed length (like 512 tokens)->\n",
        "Create a dataset class — This class will help load the jokes in batches for training."
      ],
      "metadata": {
        "id": "vuzaTT7d75Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "\n",
        "class JokeDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length=512):\n",
        "        with open(file_path, 'r') as file:\n",
        "            self.jokes = file.readlines()\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.jokes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        joke = self.jokes[idx]\n",
        "\n",
        "        # Subword tokenize the joke\n",
        "        encoding = self.tokenizer(joke,\n",
        "                                  max_length=self.max_length,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  return_tensors='pt')\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.model_max_length = 512\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.bos_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "joke_dataset = JokeDataset(file_path='laugh_factory_jokes_mod.txt', tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "print(joke_dataset[0])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4IkCOnmaqwFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model Architecture :\n",
        "Here we will be defining model architecture like how it will be initialized and how it will move forward while training.\n",
        "# Transformer Architecture\n",
        "We are using transformers here as it is best in remembering the  context because of the attention mechanism it uses.\n",
        "And this is used by almost all LLMs .\n",
        "# Components in this model\n",
        "\n",
        "\n",
        "*   Embedding layer\n",
        "*   Transformer Encoder\n",
        "*   Fully Connected Layer\n",
        "*   Forward Pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WjfU5UV_8Tdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class JokeGeneratorModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, num_heads=8, num_layers=4, max_length=512):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        - vocab_size: Size of the vocabulary\n",
        "        - embed_dim: Dimension of embeddings for tokens\n",
        "        - num_heads: Number of attention heads in the Transformer\n",
        "        - num_layers: Number of Transformer blocks (layers)\n",
        "        - max_length: Maximum sequence length\n",
        "        \"\"\"\n",
        "        super(JokeGeneratorModel, self).__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_dim)\n",
        "\n",
        "        # Transformer layer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Linear layer to convert hidden states to logits for each token in the vocab\n",
        "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        - x: Tensor of shape (batch_size, sequence_length) containing token indices\n",
        "\n",
        "        Returns:\n",
        "        - logits: Tensor of shape (batch_size, sequence_length, vocab_size)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = x.size()\n",
        "\n",
        "        # Create token embeddings and position embeddings\n",
        "        token_embeds = self.token_embedding(x)\n",
        "        position_ids = torch.arange(0, seq_len, device=x.device).unsqueeze(0).repeat(batch_size, 1)\n",
        "        position_embeds = self.position_embedding(position_ids)\n",
        "\n",
        "        # Combine embeddings and pass through the Transformer\n",
        "        x = token_embeds + position_embeds\n",
        "        x = x.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer(x)\n",
        "\n",
        "        x = transformer_output.permute(1, 0, 2)\n",
        "\n",
        "        # Generate logits for each position in the sequence\n",
        "        logits = self.fc_out(x)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "RR_D5bMoyL1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Optimizer\n",
        "Here we will declare a optimizer  which will help us during training to optimize weights according to loss.\n",
        "The optimizer updates the weights of the model after each step of backpropagation. It decides how much to adjust the weights to reduce the loss.\n",
        "# AdamW\n",
        "The optimizer used here is AdamW.\n",
        "AdamW is a variant of the Adam optimizer that decouples L2 weight decay from the gradient update rule.\n",
        "This helps prevent overfitting and makes the optimizer more stable for training deep models.\n",
        "# Loss Function\n",
        "The loss function compares the predicted tokens to the target tokens. Since we have sequential data, we use Cross-Entropy Loss.\n",
        "Compares the predicted logits  of the model to the ground-truth tokens.\n",
        "# Use of GPU(CUDA)\n",
        "Since Transformers have millions of parameters, training on a CPU would be very slow.\n",
        "By moving the model to GPU (CUDA), training can be accelerated with parallel computations on NVIDIA GPU"
      ],
      "metadata": {
        "id": "kN9z7dNm8nSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AdamW\n",
        "\n",
        "#Hyperparameters\n",
        "VOCAB_SIZE = 50257\n",
        "EMBED_DIM = 256\n",
        "NUM_HEADS = 8\n",
        "NUM_LAYERS = 4\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "#Initialize the Model\n",
        "model = JokeGeneratorModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "\n",
        "# Move Model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Loss Function\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# 5. Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n"
      ],
      "metadata": {
        "id": "Q-PxB3Tc8zGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloder:\n",
        "The DataLoader is a crucial component of the training process. It feeds data to the model in batches, ensuring smooth and efficient training. However, if GPU runs out of memory , training will crash. To avoid this, we introduce dynamic batch size adjustment.\n",
        "# Steps:\n",
        "Start with Initial Batch Size (default = 16). ->\n",
        "Test if it fits in memory. ->\n",
        "If it doesn't fit, reduce the batch size by half and try again. ->\n",
        "Repeat until it fits or the batch size reaches the minimum (default = 1)."
      ],
      "metadata": {
        "id": "xnlLyjMy9DDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataloader(dataset, initial_batch_size=16, min_batch_size=1):\n",
        "\n",
        "    batch_size = initial_batch_size\n",
        "\n",
        "    while batch_size >= min_batch_size:\n",
        "        try:\n",
        "            print(f\"Trying batch size: {batch_size}\")\n",
        "            dataloader = DataLoader(\n",
        "                dataset=dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "            )\n",
        "\n",
        "            for batch in dataloader:\n",
        "                inputs = batch['input_ids'].to('cuda')\n",
        "                targets = batch['attention_mask'].to('cuda')\n",
        "                print(f\"✅ Batch size {batch_size} fits in memory!\")\n",
        "                return dataloader\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if 'out of memory' in str(e):\n",
        "                print(f\"Batch size {batch_size} is too large, reducing by half...\")\n",
        "                torch.cuda.empty_cache()\n",
        "                batch_size //= 2\n",
        "            else:\n",
        "                print(f\" Unexpected error: {e}\")\n",
        "                break\n",
        "\n",
        "    print(f\"Could not fit any batch size larger than {min_batch_size}. Using batch size {batch_size}.\")\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=lambda x: x\n",
        "    )\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "k0Pg8PKM_R3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(joke_dataset, initial_batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHr_QDwXBYVl",
        "outputId": "56713a92-5d9c-4fdc-dc85-064c3220eb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Trying batch size: 16\n",
            "✅ Batch size 16 fits in memory!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training:\n",
        "This script focuses on loading a checkpoint if available and training the model on the dataset. The key idea is to ensure training resumes from the last saved epoch if interrupted. This approach is useful for long-running training jobs where you want to avoid restarting from scratch in case of an interruption.\n",
        "# Steps of Training:\n",
        "\n",
        "* Epoch Loop: Loop from epoch_start to epoch_start + epochs.\n",
        "* Batch Loop: Process batches using DataLoader and TQDM for a progress bar.\n",
        "* Loss Calculation: Calculate loss using CrossEntropyLoss.\n",
        "* Backward Pass: Backpropagate loss to compute gradients.\n",
        "* Optimizer Step: Update the model's parameters.\n",
        "* Loss Tracking: Keep track of total loss for each epoch"
      ],
      "metadata": {
        "id": "f2gOAJy39MI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    if os.path.isfile(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        except KeyError:\n",
        "\n",
        "            try:\n",
        "                model.load_state_dict(checkpoint)\n",
        "                optimizer.load_state_dict()\n",
        "\n",
        "            except:\n",
        "                print(\"Unable to load model state.\")\n",
        "                return model, optimizer, 0\n",
        "\n",
        "        epoch_start = checkpoint['epoch']\n",
        "        print(f\"Resuming from epoch {epoch_start + 1}\")\n",
        "        return model, optimizer, epoch_start\n",
        "    else:\n",
        "        print(\"No checkpoint found, starting from 0 \")\n",
        "        return model, optimizer, 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, epochs=5,epoch_start=0, device='cuda'):\n",
        "\n",
        "    checkpoint_path = f\"jgen_epoch_{epoch_start-1}.pth\"\n",
        "    model, optimizer, epoch_start = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "    model.train()\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(epoch_start,epoch_start+epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs+epoch_start}\")\n",
        "        total_loss = 0\n",
        "\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=f\"Training epoch {epoch+1}\"):\n",
        "\n",
        "            inputs = batch['input_ids'].to(device)\n",
        "            targets = inputs[:, 1:].contiguous()\n",
        "\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            attention_mask = attention_mask[:, 1:].contiguous()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            outputs = model(inputs[:,:-1])\n",
        "\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "            print(\"outputs-\",outputs,\" targets- \",targets)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Average Loss for epoch {epoch+1}: {avg_loss}\")\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, f\"jgen_epoch_{epoch+1}.pth\")\n",
        "        print(f\"Model saved for epoch {epoch+1}\")\n",
        "\n",
        "\n",
        "train(model, dataloader, optimizer, epochs=3,epoch_start=26)\n"
      ],
      "metadata": {
        "id": "AX7w6ljSDcIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction / Evaluation:\n",
        "Here we will predict or basically evaluate the model for the output it generate for a given prompt.\n",
        "\n",
        "# Steps:\n",
        "* Load Model & Tokenizer -Load the trained checkpoint.\n",
        "* Input Prompt- Provide an initial phrase as input. Tokenize the input and prepare it for input to the model.\n",
        "* Text Generation - Use top-k sampling to introduce randomness, making the jokes more creative.Use temperature to control randomness\n",
        "* Decoding and Display - Convert the tokenized output back to readable text using the tokenizer.\n",
        "\n"
      ],
      "metadata": {
        "id": "mn3Thf679c_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_joke(prompt, model, vocab, max_length=100, temperature=0.9, top_k=50, device='cuda'):\n",
        "\n",
        "    model.eval()\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "\n",
        "    generated_ids = input_ids\n",
        "    print(\"generated ids\",generated_ids)\n",
        "\n",
        "\n",
        "    for _ in range(max_length):\n",
        "\n",
        "        logits = model(generated_ids)[:, -1, :]\n",
        "        logits = logits / temperature\n",
        "        print(\"logits\",logits)\n",
        "\n",
        "        if top_k > 0:\n",
        "            values, indices = torch.topk(logits, top_k)\n",
        "            probs = F.softmax(values, dim=-1)\n",
        "            next_token = torch.multinomial(probs, 1)\n",
        "            next_token = indices.gather(-1, next_token)\n",
        "        else:\n",
        "            next_token = logits.argmax(dim=-1)\n",
        "\n",
        "        print(f\"Next Token: {next_token}\")\n",
        "\n",
        "        generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
        "        print(f\"Generated Tokens: {generated_ids}\")\n",
        "\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "\n",
        "    generated_tokens = generated_ids.squeeze().cpu().numpy().tolist()\n",
        "    joke = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return joke\n",
        "\n",
        "\n",
        "\n",
        "prompt = \"one day\"\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(vocab)\n",
        "checkpoint_path = \"jgen_epoch_25.pth\"\n",
        "model, optimizer, epoch_start = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "\n",
        "generated_joke = generate_joke(prompt, model, vocab)\n",
        "print(f\"Generated Joke: {generated_joke}\")\n"
      ],
      "metadata": {
        "id": "Nz_f8mc_IBbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deployment\n",
        "Now it can be deployed on multiple platforms accordingly: *like on cloud platforms GCP or AWS sagemaker, Web platforms like heroku, and by some compression on edge devices like mobiles and laptops too . And there are many other platforms too on which it can be deployed.*"
      ],
      "metadata": {
        "id": "PbqGMGUfGVy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tools used\n",
        "* Deep learning framework - Pytorch\n",
        "* Transformer by Hugging Face\n",
        "* Selenium for web Scrapping\n",
        "* And many other techniques like Softmax, Top-K Sampling , Greedy Search , Adam Optimization"
      ],
      "metadata": {
        "id": "tXDSZqmDHaRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenges\n",
        "* Dataset Collection - Finding the dataset which is good enough as a custom dataset for model training is really difficult\n",
        "* Model Training - Transfomers are computationally expensive and in terms of memory too because  it needs to store many different type of data like attention , weights etc.\n",
        "* Resource Constraints - Due to lesser computational power locally available and very limit power on the free version of google collab make it more difficult for training as after limit we have to stop the training process completely and on collab loosing the file is one  more difficulty.\n",
        "* Evaluation - Unlike other machine learning models where they have proper evaluating matrices available , these natural langage models often rely on the human feedbacks.\n",
        "\n",
        "* Similarly there are few other challenges too."
      ],
      "metadata": {
        "id": "xULD3sO4IDMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"vishwjeetthakur995@gmail.com\"\n",
        "!git config --global user.name \"vishvjeet thakur\"\n",
        "!git init\n",
        "!git add README.md\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/vishvjeet-thakur/Joke-Generator-Model.git\n",
        "!git push -u origin main\n"
      ],
      "metadata": {
        "id": "DWs26sQEQ4lU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2746fa0-d42d-40de-9d95-566d441106ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "fatal: pathspec 'README.md' did not match any files\n",
            "On branch main\n",
            "nothing to commit, working tree clean\n",
            "error: remote origin already exists.\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git remote add origin https://github.com/vishvjeet-thakur/Joke-Generator-Model.git\n",
        "# !git branch -M main\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "LTzov6daQ-jP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5d350c-83e9-4384-cdcf-ad47e1c782c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}